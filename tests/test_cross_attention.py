# æµ‹è¯•cross-attentionæ˜¯å¦çœŸçš„åœ¨å·¥ä½œ

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
from src.model import MiniTransformer, DecoderLayer, MultiHeadAttention
from config.config import config, reverse_vocab
from src.device_utils import get_device

def test_cross_attention_directly():
    """ç›´æ¥æµ‹è¯•cross-attentionå±‚"""
    print("=" * 70)
    print("ğŸ” ç›´æ¥æµ‹è¯•Cross-Attentionå±‚")
    print("=" * 70)
    
    device, _ = get_device()
    d_model = config.D_MODEL
    num_heads = config.NUM_HEADS
    
    # åˆ›å»ºcross-attentionå±‚
    cross_attn = MultiHeadAttention(d_model, num_heads).to(device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 1
    enc_len = 3
    dec_len = 1
    
    # encoderè¾“å‡ºï¼ˆä¸åŒè¾“å…¥åº”è¯¥ä¸åŒï¼‰
    enc_output1 = torch.randn(batch_size, enc_len, d_model, device=device)
    enc_output2 = torch.randn(batch_size, enc_len, d_model, device=device) * 2  # æ•…æ„ä¸åŒ
    
    # decoderè¾“å…¥ï¼ˆç›¸åŒï¼‰
    dec_input = torch.randn(batch_size, dec_len, d_model, device=device)
    
    # åˆ›å»ºmask
    enc_mask = torch.ones(batch_size, 1, dec_len, enc_len, device=device)  # å…¨éƒ¨å¯è§
    
    print(f"\næµ‹è¯•æ•°æ®:")
    print(f"  enc_output1å‡å€¼: {enc_output1.mean().item():.4f}, æ ‡å‡†å·®: {enc_output1.std().item():.4f}")
    print(f"  enc_output2å‡å€¼: {enc_output2.mean().item():.4f}, æ ‡å‡†å·®: {enc_output2.std().item():.4f}")
    print(f"  dec_inputå‡å€¼: {dec_input.mean().item():.4f}, æ ‡å‡†å·®: {dec_input.std().item():.4f}")
    
    # è¿è¡Œcross-attention
    with torch.no_grad():
        output1 = cross_attn(dec_input, enc_output1, enc_output1, mask=enc_mask)
        output2 = cross_attn(dec_input, enc_output2, enc_output2, mask=enc_mask)
    
    print(f"\nCross-Attentionè¾“å‡º:")
    print(f"  output1å‡å€¼: {output1.mean().item():.4f}, æ ‡å‡†å·®: {output1.std().item():.4f}")
    print(f"  output2å‡å€¼: {output2.mean().item():.4f}, æ ‡å‡†å·®: {output2.std().item():.4f}")
    
    diff = (output1 - output2).abs().mean().item()
    print(f"  ä¸¤ä¸ªè¾“å‡ºçš„å·®å¼‚: {diff:.6f}")
    
    if diff < 0.001:
        print(f"  âŒ è­¦å‘Šï¼šCross-Attentionè¾“å‡ºå‡ ä¹ç›¸åŒï¼Œå¯èƒ½æœ‰é—®é¢˜")
    else:
        print(f"  âœ… Cross-Attentionè¾“å‡ºä¸åŒï¼Œåº”è¯¥æ­£å¸¸å·¥ä½œ")
    
    # æµ‹è¯•2ï¼šæ£€æŸ¥æ³¨æ„åŠ›æƒé‡
    print(f"\næµ‹è¯•2ï¼šæ£€æŸ¥æ³¨æ„åŠ›æƒé‡")
    print("-" * 70)
    
    # æ‰‹åŠ¨è¿è¡Œscaled_dot_product_attentionçœ‹çœ‹æ³¨æ„åŠ›æƒé‡
    from src.model import scaled_dot_product_attention
    
    # å‡†å¤‡query, key, value
    q = cross_attn.W_q(dec_input)
    k1 = cross_attn.W_k(enc_output1)
    v1 = cross_attn.W_v(enc_output1)
    k2 = cross_attn.W_k(enc_output2)
    v2 = cross_attn.W_v(enc_output2)
    
    # split heads
    def split_heads(x, num_heads):
        batch_size, seq_len, d_model = x.size()
        d_k = d_model // num_heads
        return x.view(batch_size, seq_len, num_heads, d_k).transpose(1, 2)
    
    q_split = split_heads(q, num_heads)
    k1_split = split_heads(k1, num_heads)
    v1_split = split_heads(v1, num_heads)
    k2_split = split_heads(k2, num_heads)
    v2_split = split_heads(v2, num_heads)
    
    # è°ƒæ•´maskå½¢çŠ¶
    mask_adjusted = enc_mask.unsqueeze(1)  # [batch, 1, 1, dec_len, enc_len] -> éœ€è¦è°ƒæ•´
    
    # è¿è¡Œattention
    attn_output1, attn_weights1 = scaled_dot_product_attention(q_split, k1_split, v1_split, mask=enc_mask)
    attn_output2, attn_weights2 = scaled_dot_product_attention(q_split, k2_split, v2_split, mask=enc_mask)
    
    print(f"  æ³¨æ„åŠ›æƒé‡1å½¢çŠ¶: {attn_weights1.shape}")
    print(f"  æ³¨æ„åŠ›æƒé‡1 (ç¬¬ä¸€ä¸ªhead, ç¬¬ä¸€ä¸ªquery): {attn_weights1[0, 0, 0].detach().cpu().numpy()}")
    print(f"  æ³¨æ„åŠ›æƒé‡2 (ç¬¬ä¸€ä¸ªhead, ç¬¬ä¸€ä¸ªquery): {attn_weights2[0, 0, 0].detach().cpu().numpy()}")
    
    attn_diff = (attn_weights1 - attn_weights2).abs().mean().item()
    print(f"  æ³¨æ„åŠ›æƒé‡å·®å¼‚: {attn_diff:.6f}")
    
    if attn_diff < 0.001:
        print(f"  âŒ è­¦å‘Šï¼šæ³¨æ„åŠ›æƒé‡å‡ ä¹ç›¸åŒï¼")
    else:
        print(f"  âœ… æ³¨æ„åŠ›æƒé‡ä¸åŒï¼Œåº”è¯¥æ­£å¸¸")
    
    print("\n" + "=" * 70)

def test_full_model_cross_attention():
    """æµ‹è¯•å®Œæ•´æ¨¡å‹çš„cross-attention"""
    print("\n" + "=" * 70)
    print("ğŸ” æµ‹è¯•å®Œæ•´æ¨¡å‹çš„Cross-Attention")
    print("=" * 70)
    
    device, _ = get_device()
    model = MiniTransformer()
    model = model.to(device)
    model.eval()
    
    vocab = config.VOCAB
    
    # ä¸¤ä¸ªä¸åŒçš„encoderè¾“å…¥
    enc_input1 = torch.tensor([[vocab['a'], vocab['b'], vocab['c']]], device=device)
    enc_input2 = torch.tensor([[vocab['c'], vocab['b'], vocab['a']]], device=device)
    dec_input = torch.tensor([[vocab['<sos>']]], device=device)
    
    from src.mask_utils import create_decoder_mask, create_padding_mask
    
    # è¿è¡Œencoder
    enc_emb1 = model.embedding(enc_input1)
    enc_emb2 = model.embedding(enc_input2)
    enc_mask1 = create_padding_mask(enc_input1)
    enc_mask2 = create_padding_mask(enc_input2)
    
    if isinstance(model.encoder, nn.ModuleList):
        enc_output1 = enc_emb1
        enc_output2 = enc_emb2
        for encoder_layer in model.encoder:
            enc_output1 = encoder_layer(enc_output1, padding_mask=enc_mask1)
            enc_output2 = encoder_layer(enc_output2, padding_mask=enc_mask2)
    else:
        enc_output1 = model.encoder(enc_emb1, padding_mask=enc_mask1)
        enc_output2 = model.encoder(enc_emb2, padding_mask=enc_mask2)
    
    print(f"\nEncoderè¾“å‡º:")
    print(f"  enc_output1å‡å€¼: {enc_output1.mean().item():.6f}")
    print(f"  enc_output2å‡å€¼: {enc_output2.mean().item():.6f}")
    enc_diff = (enc_output1 - enc_output2).abs().mean().item()
    print(f"  Encoderè¾“å‡ºå·®å¼‚: {enc_diff:.6f}")
    
    # è¿è¡Œdecoderçš„ç¬¬ä¸€å±‚
    dec_emb = model.embedding(dec_input)
    dec_mask = create_decoder_mask(dec_input)
    
    if hasattr(model.decoder, "layers"):
        decoder_layer = model.decoder.layers[0]
    elif isinstance(model.decoder, nn.ModuleList):
        decoder_layer = model.decoder[0]
    else:
        decoder_layer = model.decoder
    
    # åˆ›å»ºenc_dec_mask
    batch_size, _, _, enc_len = enc_mask1.shape
    dec_len = dec_input.shape[1]
    enc_dec_mask1 = enc_mask1.expand(batch_size, 1, dec_len, enc_len)
    enc_dec_mask2 = enc_mask2.expand(batch_size, 1, dec_len, enc_len)
    
    # ç¬¬ä¸€æ­¥ï¼šself-attention
    masked_attn_out = decoder_layer.masked_attn(dec_emb, dec_emb, dec_emb, dec_mask)
    x = decoder_layer.norm1(dec_emb + masked_attn_out)
    
    # ç¬¬äºŒæ­¥ï¼šcross-attentionï¼ˆå…³é”®ï¼ï¼‰
    print(f"\nCross-Attention:")
    print(f"  query (x)å½¢çŠ¶: {x.shape}")
    print(f"  key/value (enc_output1)å½¢çŠ¶: {enc_output1.shape}")
    print(f"  maskå½¢çŠ¶: {enc_dec_mask1.shape}")
    
    cross_attn_out1 = decoder_layer.enc_dec_attn(x, enc_output1, enc_output1, mask=enc_dec_mask1)
    cross_attn_out2 = decoder_layer.enc_dec_attn(x, enc_output2, enc_output2, mask=enc_dec_mask2)
    
    print(f"  cross_attn_out1å‡å€¼: {cross_attn_out1.mean().item():.6f}")
    print(f"  cross_attn_out2å‡å€¼: {cross_attn_out2.mean().item():.6f}")
    cross_diff = (cross_attn_out1 - cross_attn_out2).abs().mean().item()
    print(f"  Cross-Attentionè¾“å‡ºå·®å¼‚: {cross_diff:.6f}")
    
    if cross_diff < 0.001:
        print(f"  âŒ é—®é¢˜ç¡®è®¤ï¼šCross-Attentionè¾“å‡ºå‡ ä¹ç›¸åŒï¼")
        print(f"     è¿™è¯´æ˜Cross-Attentionæ²¡æœ‰æ­£ç¡®ä½¿ç”¨Encoderä¿¡æ¯")
    else:
        print(f"  âœ… Cross-Attentionè¾“å‡ºä¸åŒï¼Œåº”è¯¥æ­£å¸¸")
    
    print("\n" + "=" * 70)

if __name__ == "__main__":
    test_cross_attention_directly()
    test_full_model_cross_attention()

